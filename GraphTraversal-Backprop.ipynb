{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e12adf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b790ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Variable:\n",
    "  def __init__(self,value, local_grads={}):\n",
    "    self.value = value\n",
    "    self.local_grads  = local_grads\n",
    "    \n",
    "  def __repr__(self):\n",
    "    return f\"Value(data={self.value})\"\n",
    "\n",
    "  def __add__(self,other):\n",
    "    other = other if isinstance(other,Variable) else Variable(other)\n",
    "        \n",
    "    local_grads = ((self,1),(other,1))\n",
    "    return Variable(self.value+other.value , local_grads)\n",
    "    \n",
    "\n",
    "  def __mul__(self,other):\n",
    "    \n",
    "    other = other if isinstance(other,Variable) else Variable(other)\n",
    "            \n",
    "    local_grads = ((self,other.value),(other,self.value))\n",
    "    \n",
    "    return Variable(self.value*other.value,local_grads)\n",
    "    \n",
    "  def neg(self):\n",
    "    local_grads = ((self,-1))\n",
    "    return Variable(-1*self.value,local_grads)\n",
    "\n",
    "  def __sub__(self,other):\n",
    "    #other = other if isinstance(other,Variable) else Variable(other)\n",
    "       \n",
    "    #local_grads = ((self,1),(other,-1))\n",
    "    #return Variable(self.value-other.value,local_grads)\n",
    "    \n",
    "    return self + (neg(other))\n",
    "  \n",
    "  def inv(self):\n",
    "    local_grads = ((self,-1/(self.value)**2))\n",
    "    \n",
    "    return Variable(1/(self.value),local_grads)\n",
    "                   \n",
    "  def __truediv__(self,other):\n",
    "                   \n",
    "    other = other if isinstance(other,Variable) else Variable(other)\n",
    "                 \n",
    "    local_grads = ((self,1/other.value),(other,-(self.value)/(other.value)**2))\n",
    "    return Variable(self.value/other.value,local_grads)\n",
    "            \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ff725f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(10).__truediv__(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b46e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa600d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Variable(9)\n",
    "d = 1.1\n",
    "c-d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c5ea1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grads(variable):\n",
    "  \n",
    "  gradients = defaultdict(lambda:0)\n",
    "\n",
    "  def compute_gradients(variable,path_value):\n",
    "    for node, grad in variable.local_grads:\n",
    "      midvalue = grad*path_value\n",
    "      gradients[node] += midvalue\n",
    "      compute_gradients(node, midvalue)\n",
    "  compute_gradients(variable,1)\n",
    "  return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34415a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.dot([Variable(2),a,b],[Variable(4),b,a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09897442",
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(c,Variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f530b0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Variable(3)\n",
    "b = Variable(4)\n",
    "c = Variable(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf1f26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.local_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6ca8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(a,b):\n",
    "    return (a/b -a)*(b/a +a +b)*(a-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e59374",
   "metadata": {},
   "outputs": [],
   "source": [
    "a/b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a96aac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = f(a,b)\n",
    "get_grads(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c38dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e3a24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_var = np.vectorize(lambda x: Variable(x))\n",
    "\n",
    "to_vals = np.vectorize(lambda variable : variable.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b252d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcebbef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(weights, gradients, lr):\n",
    "    for _,weight in np.denumerate(weights):\n",
    "        weight.value -= lr*(gradients[weight])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c63e0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262ac71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = to_var(np.random.random(input_size))\n",
    "\n",
    "y_true = to_var(lambda x:x**2)\n",
    "\n",
    "weights = to_var(np.random.random((input_size,input_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78c7226",
   "metadata": {},
   "outputs": [],
   "source": [
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce34695",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_vals = []\n",
    "for i in range(100):\n",
    "    y_pred = np.dot(x, weights)\n",
    "    loss = np.sum((y_true-y_pred)**2)\n",
    "    loss_vals.append(loss.value)\n",
    "    gradients = get_gradients(loss)\n",
    "    update_weights(weights, gradients, lr)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419695fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeea0910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3d0f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59b85f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    def __init__(self,nin,nouts):\n",
    "        self.w = [Variable(random.uniform(-1,1) for _ in range(nouts))]\n",
    "        self.b = Variable(random.unifrom(-1,1))\n",
    "    def __call__(self,x):\n",
    "        act = sum((wi*xi for wi,xi in zip(self.w,x) ) + self.b)\n",
    "        #out = act.tanh() we have yet to define tanh fucntion in Variable.\n",
    "        return out\n",
    "    \n",
    "class Layer:\n",
    "    def __init__(self,nin,nout):\n",
    "        self.w = np.random.rand(nin,nout)\n",
    "        self.b = np.random.rand(nout)\n",
    "    def __call__(self,x):\n",
    "        out = np.dot(x,self.w) + self.b\n",
    "        #out = out.tanh()\n",
    "        return out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return np.concatenate((self.w,self.b),axis=0)  \n",
    "    \n",
    "class MLP:\n",
    "    def __init__(self,nin,nouts):\n",
    "        #nouts refers to array of layers like [4,4,1] represesnts 4neurons + 4neuron + 1 neuron\n",
    "        size = [nin] + nouts\n",
    "        self.layers = [Layer(size[i],size[i+1]) for i in range(len(nouts))]\n",
    "    def __call__(self,x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    def parameters(self):\n",
    "        return [p for p in self.layers for p in p.parameters]\n",
    "                       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ed1f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = MLP(2,[4,4,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b46583",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [[1,2],\n",
    "    [3,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b23b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "n(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739a3d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#same boilerplater code and our input will fit to any function\n",
    "\n",
    "x = to_var(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ec0033",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8350570a",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = to_var(MLP.parameters) \n",
    "\n",
    "for i in range(10):\n",
    "    y_pred = n(x)\n",
    "    loss = (y_true-y_pred) #L1 loss\n",
    "    gradients = get_grads(loss)\n",
    "    update_weights(weights,gradients, lr)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
